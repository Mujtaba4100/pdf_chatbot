# ğŸ” Multi-PDF RAG System

A production-ready, full-stack Retrieval-Augmented Generation (RAG) application that allows users to upload multiple PDFs and query them using AI. The system features **persistent embeddings** so documents are processed once and never need re-embedding on restart.

![RAG System](https://img.shields.io/badge/RAG-System-blue) ![Python](https://img.shields.io/badge/Python-3.10+-green) ![React](https://img.shields.io/badge/React-19-blue) ![FastAPI](https://img.shields.io/badge/FastAPI-0.109-teal)

---

## ğŸ“‹ Table of Contents

- [What is RAG?](#-what-is-rag)
- [System Architecture](#-system-architecture)
- [Features](#-features)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Running the Application](#-running-the-application)
- [API Documentation](#-api-documentation)
- [How It Works](#-how-it-works)
- [Persistence Mechanism](#-persistence-mechanism)
- [Duplicate Handling](#-duplicate-handling)

---

## ğŸ§  What is RAG?

**Retrieval-Augmented Generation (RAG)** is an AI architecture that enhances Large Language Models (LLMs) by providing them with relevant context retrieved from a knowledge base before generating responses.

### Traditional LLM vs RAG

| Traditional LLM | RAG System |
|----------------|------------|
| Relies on training data only | Retrieves relevant documents at query time |
| May hallucinate facts | Grounds answers in actual documents |
| Static knowledge | Dynamic, updatable knowledge base |
| Generic responses | Context-specific, accurate answers |

### RAG Pipeline Steps

1. **Document Ingestion**: Upload PDFs â†’ Extract text â†’ Chunk into smaller pieces
2. **Embedding Generation**: Convert text chunks into numerical vectors using SentenceTransformers
3. **Vector Storage**: Store embeddings in FAISS for fast similarity search
4. **Query Processing**: Embed user question â†’ Find similar chunks â†’ Retrieve context
5. **Answer Generation**: Send context + question to LLM (Gemini) â†’ Generate grounded answer

---

## ğŸ— System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        REACT FRONTEND                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚PDF Uploadâ”‚  â”‚Document List â”‚  â”‚Question/Answer Panel  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚               â”‚                      â”‚
        â–¼               â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FASTAPI BACKEND                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚/upload-pdfsâ”‚  â”‚/documents  â”‚  â”‚/ask                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚                     â”‚
         â–¼               â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       RAG ENGINE                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ SentenceTransformers â”‚ FAISS Index â”‚ Gemini API            â”‚ â”‚
â”‚  â”‚ (all-MiniLM-L6-v2)   â”‚ (Vector DB) â”‚ (Text Generation)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PERSISTENT STORAGE                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ faiss.index  â”‚  â”‚ metadata.jsonâ”‚  â”‚ documents.json   â”‚      â”‚
â”‚  â”‚ (Embeddings) â”‚  â”‚ (Chunk data) â”‚  â”‚ (Doc registry)   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

### Backend Features
- âœ… Multiple PDF upload processing
- âœ… Page-wise text extraction with PyPDF2
- âœ… **OCR support for extracting text from images in PDFs** (Tesseract)
- âœ… Text chunking with configurable overlap
- âœ… Embedding generation using all-MiniLM-L6-v2
- âœ… FAISS vector storage for fast similarity search
- âœ… Persistent storage (survives restarts)
- âœ… Duplicate detection via SHA-256 hashing
- âœ… Document registry management
- âœ… Context-grounded answer generation with Gemini
- âœ… **Smart source verification - only cites chunks that support the answer**
- âœ… Source citations with file and page numbers

### Frontend Features
- âœ… Drag-and-drop PDF upload
- âœ… Multiple file selection
- âœ… **Progressive disclosure UI - clean, focused interface**
- âœ… Uploaded documents list with metadata
- âœ… Duplicate document warning modal
- âœ… Question input with loading states
- âœ… Answer display with source citations
- âœ… System statistics panel
- âœ… Toast notifications
- âœ… Responsive design

---

## ğŸ›  Tech Stack

### Backend
| Technology | Purpose |
|------------|---------|
| **Python 3.10+** | Core language |
| **FastAPI** | REST API framework |
| **FAISS** | Vector similarity search |
| **SentenceTransformers** | Text embeddings |
| **Google Gemini** | LLM for answer generation |
| **PyPDF2** | PDF text extraction |
| **Tesseract OCR** | Extract text from images |
| **Pillow** | Image processing |
| **Pydantic** | Data validation |
| **Uvicorn** | ASGI server |

### Frontend
| Technology | Purpose |
|------------|---------|
| **React 19** | UI framework |
| **Vite** | Build tool |
| **Plain CSS** | Styling |

---

## ğŸ“ Project Structure

```
pdf_chatbot/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application & endpoints
â”‚   â”œâ”€â”€ rag_engine.py        # Core RAG pipeline logic
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ storage/
â”‚       â”œâ”€â”€ faiss.index      # Persisted FAISS embeddings
â”‚       â”œâ”€â”€ metadata.json    # Chunk text & source info
â”‚       â””â”€â”€ documents.json   # Document registry
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx              # Main React component
â”‚   â”‚   â”œâ”€â”€ App.css              # Application styles
â”‚   â”‚   â”œâ”€â”€ index.css            # Global styles
â”‚   â”‚   â”œâ”€â”€ main.jsx             # React entry point
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ PDFUpload.jsx    # File upload component
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentList.jsx # Document display component
â”‚   â”‚   â”‚   â”œâ”€â”€ QuestionAnswer.jsx # Q&A interface
â”‚   â”‚   â”‚   â”œâ”€â”€ DuplicateModal.jsx # Duplicate handling modal
â”‚   â”‚   â”‚   â”œâ”€â”€ StatsPanel.jsx   # Statistics display
â”‚   â”‚   â”‚   â””â”€â”€ Toast.jsx        # Notification component
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.js           # API communication service
â”‚   â”œâ”€â”€ public/              # Static assets
â”‚   â”œâ”€â”€ index.html           # HTML entry point
â”‚   â”œâ”€â”€ package.json         # Node.js dependencies
â”‚   â”œâ”€â”€ vite.config.js       # Vite configuration
â”‚   â””â”€â”€ eslint.config.js     # ESLint configuration
â”‚
â””â”€â”€ README.md                # This file
```

---

## ğŸš€ Installation

### Prerequisites

- Python 3.10 or higher
- Node.js 18 or higher
- npm or yarn
- **Tesseract OCR** (for image text extraction - see [OCR Setup Guide](OCR_SETUP.md))

### 1. Clone/Navigate to Project

```bash
cd "e:\AI DMS\pdf_chatbot"
```

### 2. Backend Setup

```bash
# Create virtual environment (if not exists)
python -m venv venv

# Activate virtual environment
# Windows:
.\venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install Python dependencies
cd backend
pip install -r requirements.txt
```

### 3. OCR Setup (Optional but Recommended)

To enable text extraction from images in PDFs:

**Quick Setup (Windows):**
```powershell
# Run the automated setup script
.\install_ocr.ps1
```

**Manual Setup:**
See [OCR_SETUP.md](OCR_SETUP.md) for detailed instructions.

**Note:** The system works without OCR but will skip image text extraction. If Tesseract is not installed, you'll see a warning message, but regular PDF text extraction continues normally.

### 4. Frontend Setup

```bash
# From project root, navigate to frontend folder
cd frontend
npm install
```

### 5. Configure API Key (Optional)

The Gemini API key is pre-configured. To use your own:

1. Get an API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Set environment variable:
   ```bash
   # Windows
   set GEMINI_API_KEY=your_api_key_here
   
   # macOS/Linux
   export GEMINI_API_KEY=your_api_key_here
   ```

---

## â–¶ï¸ Running the Application

### Start Backend Server

```bash
# From backend directory
cd backend
python main.py
```

Or with uvicorn directly:
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

The backend runs at: `http://localhost:8000`

### Start Frontend Development Server

```bash
# From frontend directory (new terminal)
cd frontend
npm run dev
```

The frontend runs at: `http://localhost:5173`

### Access the Application

Open your browser and navigate to: `http://localhost:5173`

---

## ğŸ“¡ API Documentation

### Endpoints

#### `POST /upload-pdfs`
Upload multiple PDF files.

**Request:** `multipart/form-data` with files

**Response:**
```json
[
  {
    "status": "success",
    "filename": "document.pdf",
    "message": "Document processed successfully",
    "chunks": 45,
    "pages": 10
  }
]
```

#### `POST /ask`
Ask a question about uploaded documents.

**Request:**
```json
{
  "question": "What is machine learning?",
  "top_k": 5
}
```

**Response:**
```json
{
  "answer": "Machine learning is a subset of AI...",
  "sources": [
    {"file": "AI_DMS.pdf", "page": 3},
    {"file": "ML_Guide.pdf", "page": 7}
  ],
  "num_chunks_used": 5
}
```

#### `GET /documents`
Get list of all uploaded documents.

**Response:**
```json
[
  {
    "doc_id": "doc_1_1640000000",
    "filename": "AI_DMS.pdf",
    "hash": "sha256...",
    "upload_timestamp": "2026-01-01T12:00:00",
    "num_chunks": 45,
    "num_pages": 10
  }
]
```

#### `DELETE /documents/{doc_id}`
Delete a document and its embeddings.

#### `GET /stats`
Get system statistics.

#### `GET /health`
Health check endpoint.

---

## ğŸ”„ How It Works

### Document Upload Flow

```
PDF File â†’ Extract Text (Page-wise) â†’ Chunk Text (200 words, 50 overlap)
    â†’ Generate Embeddings (all-MiniLM-L6-v2) â†’ Store in FAISS
    â†’ Save metadata (text, source, page) â†’ Update document registry
```

### Query Flow

```
User Question â†’ Generate Embedding â†’ FAISS Similarity Search
    â†’ Retrieve Top-K Chunks â†’ Build Context â†’ Send to Gemini
    â†’ Generate Grounded Answer â†’ Return with Sources
```

---

## ğŸ’¾ Persistence Mechanism

The system uses three persistent files:

### 1. `faiss.index`
- Binary file containing all document embeddings
- Loaded automatically on startup
- Uses FAISS's native serialization

### 2. `metadata.json`
- JSON file with chunk information:
  ```json
  [
    {
      "text": "chunk text content...",
      "source": "document.pdf",
      "page": 1
    }
  ]
  ```

### 3. `documents.json`
- Document registry:
  ```json
  {
    "doc_1_1640000000": {
      "filename": "document.pdf",
      "hash": "sha256...",
      "upload_timestamp": "2026-01-01T12:00:00",
      "num_chunks": 45,
      "num_pages": 10
    }
  }
  ```

### On Application Restart

1. Checks for existing storage files
2. Loads FAISS index with embeddings
3. Loads metadata and document registry
4. **NO re-embedding** - documents are immediately queryable

---

## ğŸ”„ Duplicate Handling

When uploading a PDF, the system:

1. **Computes SHA-256 hash** of file content
2. **Checks against document registry**
3. If duplicate found, presents options:
   - **Use Existing**: Reuse existing embeddings (no processing)
   - **Replace**: Re-process document, update embeddings
   - **Cancel**: Abort upload

This ensures:
- No unnecessary reprocessing
- Clear user control over duplicates
- Efficient storage usage

---

## ğŸ¯ Key Design Decisions

### Why No LangChain?
- **Simplicity**: Direct API calls are easier to debug
- **Performance**: Less abstraction overhead
- **Control**: Full visibility into the RAG pipeline
- **Learning**: Better understanding of how RAG works

### Why FAISS?
- **Speed**: Highly optimized for similarity search
- **Persistence**: Native save/load functionality
- **Scalability**: Handles millions of vectors efficiently
- **Simplicity**: Easy to use for L2 distance search

### Why SentenceTransformers?
- **Quality**: all-MiniLM-L6-v2 provides excellent embeddings
- **Speed**: Fast encoding even on CPU
- **Size**: Compact model (80MB)
- **No API costs**: Runs locally

---

## ğŸ”’ Security Notes

- API keys should be stored in environment variables for production
- The frontend never exposes embeddings or API keys
- All PDF processing happens server-side
- CORS is configured for local development

---

## ğŸ› Troubleshooting

### Backend won't start
- Ensure Python 3.10+ is installed
- Activate virtual environment
- Install all dependencies: `pip install -r requirements.txt`

### Frontend can't connect to backend
- Check backend is running on port 8000
- Verify CORS settings in `main.py`
- Check browser console for errors

### Embedding model download
- First run downloads the model (~80MB)
- Ensure internet connection for first startup
- Model is cached for subsequent runs

---

## ğŸ“ License

This project is for educational purposes.

---

## ğŸ‘¨â€ğŸ’» Author

Built as a demonstration of production-ready RAG systems with persistent embeddings.

---

## ğŸ™ Acknowledgments

- [SentenceTransformers](https://www.sbert.net/) for embedding models
- [FAISS](https://github.com/facebookresearch/faiss) for vector search
- [FastAPI](https://fastapi.tiangolo.com/) for the excellent web framework
- [Google Gemini](https://ai.google.dev/) for text generation
